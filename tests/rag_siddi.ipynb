{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "from llama_index.readers.file.markdown import MarkdownReader\n",
    "\n",
    "parser = MarkdownReader()\n",
    "file_extractor = {\".md\": parser}\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files= [\"/home/drunkwcodes/projects/myfoam/kb/package_manager/pdm.md\"], file_extractor=file_extractor\n",
    ").load_data()\n",
    "# documents = SimpleDirectoryReader(input_files= [\"/home/drunkwcodes/projects/myfoam/kb/package_manager/pdm.md\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.file import PDFReader\n",
    "\n",
    "# PDF Reader with `SimpleDirectoryReader`\n",
    "parser = PDFReader()\n",
    "file_extractor = {\".pdf\": parser}\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files= [\"/home/drunkwcodes/Documents/大家的日本语1-2册教材/01.pdf\"], file_extractor=file_extractor\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "embed_model = HuggingFaceEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create client\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"japanese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embedding to disk\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context, embed_model=embed_model\n",
    ")\n",
    "\n",
    "# The VectorStoreIndex class, in conjunction with the storage_context (which points to the ChromaDB collection), \n",
    "# stores these embeddings and their corresponding document metadata in the specified ChromaDB collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk\n",
    "db2 = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "chroma_collection = db2.get_or_create_collection(\"japanese\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    "    embed_model=embed_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3.2\", request_timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Data from the persisted index\n",
    "query_engine = index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "工程師的日文包括以下几个方面：\n",
      "\n",
      "1.  **職業關係語**：例如「先生」、「主任」、「工程師」，使用於與對方的職業或地位建立關係時。\n",
      "2.  **工作相關詞彙**：如“設計”、“建造”、“檢查”等，描述工程师的工作過程和實際。\n",
      "3.  **日常生活中可能遇到的情況**：例如“休息”、“旅行”、“購物”，使用於描述工程师在工作之外的生活經歷。\n",
      "4.  **專業關係語**：如“報告”、“評估”、“監管”等，描述工程师與對方之間的職業關係和互動。\n",
      "\n",
      "以下是一些日文例句：\n",
      "\n",
      "*   「こんにちは、 Mr. Smith-san です。私はエンジニアです。」（中文翻譯：「hello，Mr. Smith先生，我是工程師。\"])\n",
      "*   「このプロジェクトでは、設計と建造を担当することになります。」（中文翻譯：`這個項目中，我們負責設計和建造。`)\n",
      "*   「今日は休息日です。 tomorrow は仕事に戻ります。」（中文翻譯：`今天是休息日，明天我們再回工作。`)\n",
      "*   「このプロジェクトの評価をします」という言葉で「報告」、「評估」的意義被表達出。\n",
      "*   「彼はエンジニアです。彼が仕事をしている間には、毎日同じルートを走ります。」（中文翻譯：`他人是工程師，他的工作時間每天走一樣路。`)\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"工程師的日文？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
